## Introduce LQ FullyConnected

### What?

Lets introduce layer with binary quantization of weights and activation.

### Why?

It could give to us ability make large compression of networks  with fast inference on low-end devices.

